{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44348b8f",
   "metadata": {},
   "source": [
    "### Loading and Saving Room00 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b0888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fa9b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pickle.load(open(\"./data/continuous_sections_60_train.pickle\", \"rb\"))\n",
    "test_data = pickle.load(open(\"./data/continuous_sections_60_test.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a0e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data = pd.DataFrame()\n",
    "for frame_idx, frame_data in enumerate(train_data['room00']):\n",
    "    frame_data['frame_id'] = frame_idx\n",
    "    new_train_data = pd.concat([new_train_data, frame_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a1daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9de18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data = pd.DataFrame()\n",
    "for frame_idx, frame_data in enumerate(test_data['room00']):\n",
    "    frame_data['frame_id'] = frame_idx\n",
    "    new_test_data = pd.concat([new_test_data, frame_data])\n",
    "new_test_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0925ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_data.to_csv(\"./data/train_room00.csv\")\n",
    "new_test_data.to_csv(\"./data/test_room00.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74ed878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the scaling statistics of the training data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std = StandardScaler()\n",
    "std_X_train = std.fit_transform(new_train_data.drop(columns = ['frame_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583f82e1",
   "metadata": {},
   "source": [
    "### Preprocessing Data for 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e1dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequence(sequence, n_steps_in, out_steps, output_var):\n",
    "    X, y = list(), list()\n",
    "    seq_len = sequence.shape[0]\n",
    "    sequence.index = range(sequence.shape[0])\n",
    "    sequence.drop(columns = ['frame_id'], inplace=True)\n",
    "    for i in range(0, seq_len):\n",
    "        end_idx = i + (n_steps_in-1)\n",
    "        out_idx = end_idx + out_steps\n",
    "        if out_idx >= seq_len:\n",
    "            break\n",
    "            \n",
    "        seq_x = sequence.loc[i:end_idx, :]\n",
    "        seq_x = seq_x.values\n",
    "        \n",
    "        seq_y = sequence.loc[out_idx, output_var]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "        \n",
    "        \n",
    "    return np.asarray(X).astype(np.float32), np.asarray(y).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fac13",
   "metadata": {},
   "source": [
    "### Training and testing data processing for 1D-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd384d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "unique_frames = np.unique(new_train_data.frame_id)\n",
    "first_frame = unique_frames[0]\n",
    "seq_train_X, seq_train_Y = split_sequence(\n",
    "    new_train_data.loc[new_train_data.frame_id == first_frame, :],\n",
    "    5, 5, 'co2'\n",
    ")\n",
    "\n",
    "for f_id in tqdm(unique_frames):\n",
    "    if f_id != first_frame:\n",
    "        frame_X, frame_y = split_sequence(\n",
    "            new_train_data.loc[new_train_data.frame_id == f_id, :],\n",
    "            5, 5, 'co2'\n",
    "        )\n",
    "        seq_train_X = np.concatenate((seq_train_X, frame_X))\n",
    "        seq_train_Y = np.concatenate((seq_train_Y, frame_y))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8147667",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_frames = np.unique(new_test_data.frame_id)\n",
    "first_frame = unique_frames[0]\n",
    "seq_test_X, seq_test_Y = split_sequence(\n",
    "    new_test_data.loc[new_test_data.frame_id == first_frame, :],\n",
    "    5, 5, 'co2'\n",
    ")\n",
    "\n",
    "for f_id in tqdm(unique_frames):\n",
    "    if f_id != first_frame:\n",
    "        frame_X, frame_y = split_sequence(\n",
    "            new_test_data.loc[new_test_data.frame_id == f_id, :],\n",
    "            5, 5, 'co2'\n",
    "        )\n",
    "        seq_test_X = np.concatenate((seq_test_X, frame_X))\n",
    "        seq_test_Y = np.concatenate((seq_test_Y, frame_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059edcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the relationship type\n",
    "seq_train_X[:, [1, 2]] = seq_train_X[:, [2, 1]]\n",
    "seq_test_X[:, [1, 2]] = seq_test_X[:, [2, 1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbed523",
   "metadata": {},
   "source": [
    "### Creating the loader and the 1D-CNN model for the DL regression Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c9ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, scaler, feature_values, output_values):\n",
    "        self.mean = scaler.mean_\n",
    "        self.std = np.sqrt(scaler.var_)\n",
    "        self.feature_values = feature_values\n",
    "        self.output_values = output_values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.feature_values.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature_vals = self.feature_values[idx]\n",
    "        feature_vals = (feature_vals - self.mean) / (self.std)\n",
    "        label = self.output_values[idx]\n",
    "        \n",
    "        return feature_vals, label\n",
    "    \n",
    "class OneDCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, nb_features):\n",
    "        super(OneDCNN, self).__init__()\n",
    "        self.nb_features = nb_features\n",
    "        self.conv1 = nn.Conv1d(self.nb_features, 32, kernel_size = 1)\n",
    "        self.fc1 = nn.Linear(160, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.conv1(X))\n",
    "        X = X.reshape(-1, np.prod(X.shape[1:]))\n",
    "        X = F.relu(self.fc1(X))\n",
    "        X = F.relu(self.fc2(X))\n",
    "        X = F.relu(self.fc3(X))\n",
    "        \n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29681b92",
   "metadata": {},
   "source": [
    "### Training of the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf4289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(cnn_model, train_loader, device, nb_epochs = 1):\n",
    "    optimizer = torch.optim.Adam(cnn_model.parameters(), lr = 1e-3)\n",
    "    error = nn.MSELoss()\n",
    "    cnn_model = cnn_model.to(device)\n",
    "    cnn_model.train()\n",
    "    set_epoch_loss = []\n",
    "    for epoch in range(nb_epochs):\n",
    "        set_losses = []\n",
    "        for batch_idx, (feature_batch, y_batch) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            var_X_batch = feature_batch.float().to(device)\n",
    "            y_batch = y_batch.float().to(device)\n",
    "            output = cnn_model(var_X_batch)\n",
    "            loss = error(output.reshape(-1,), y_batch)\n",
    "            set_losses.append(loss.cpu().detach().numpy())\n",
    "            if batch_idx % 5000 == 0:\n",
    "                print(f\"Epoch: {epoch+1}/{nb_epochs}, Batch: {batch_idx}, Loss: {np.mean(set_losses)}\")\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        set_epoch_loss.extend(set_losses)\n",
    "    \n",
    "    return set_epoch_loss\n",
    "\n",
    "def evaluate(cnn_model, test_loader, device):\n",
    "    predicted_values, output_values = [], []\n",
    "    \n",
    "    cnn_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (X_test, y_test) in enumerate(test_loader):\n",
    "            X_test = X_test.float().to(device)\n",
    "            pred_values = cnn_model(X_test)\n",
    "            predicted_values.extend(pred_values.reshape(-1,).cpu().detach().numpy())\n",
    "            output_values.extend(y_test.numpy())\n",
    "            \n",
    "    \n",
    "    return predicted_values, output_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967be1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = CustomDataset(std, seq_train_X, seq_train_Y)\n",
    "training_loader = DataLoader(training_dataset, batch_size = 16, shuffle = True)\n",
    "\n",
    "testing_dataset = CustomDataset(std, seq_test_X, seq_test_Y)\n",
    "testing_loader = DataLoader(testing_dataset, batch_size = 16, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b9654",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33728efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = OneDCNN(nb_features = 5)\n",
    "set_epoch_loss = fit_model(cnn_model, training_loader, device, nb_epochs = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcd5e61",
   "metadata": {},
   "source": [
    "### Creating the dataset loader for AE model and the AE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e9d76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE_all(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_values):\n",
    "        super(AE_all, self).__init__()\n",
    "        self.features = input_values\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(self.features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, self.features)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "    \n",
    "class ActivationsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, feature_values):\n",
    "        self.features = feature_values\n",
    "#         self.output = feature_values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature_vals = self.features[idx]\n",
    "        label = self.features[idx]\n",
    "        \n",
    "        return feature_vals, label\n",
    "\n",
    "def fit_ae_model(ae_model, train_loader, device, nb_epochs = 1):\n",
    "    optimizer = torch.optim.Adam(ae_model.parameters(), lr = 1e-3)\n",
    "    error = nn.MSELoss()\n",
    "    ae_model = ae_model.to(device)\n",
    "    ae_model.train()\n",
    "    set_epoch_loss = []\n",
    "    for epoch in range(nb_epochs):\n",
    "        set_losses = []\n",
    "        for batch_idx, (feature_batch, y_batch) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            var_X_batch = feature_batch.float().to(device)\n",
    "            y_batch = y_batch.float().to(device)\n",
    "            output = ae_model(var_X_batch)\n",
    "            loss = error(output, y_batch)\n",
    "            set_losses.append(loss.cpu().detach().numpy())\n",
    "            if batch_idx % 5000 == 0:\n",
    "                print(f\"Epoch: {epoch+1}/{nb_epochs}, Batch: {batch_idx}, Loss: {np.mean(set_losses)}\")\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        set_epoch_loss.extend(set_losses)\n",
    "    \n",
    "    return set_epoch_loss\n",
    "\n",
    "def evaluate_ae(ae_model, test_loader, device):\n",
    "    predicted_values = torch.Tensor()\n",
    "    output_values = torch.Tensor()\n",
    "    \n",
    "    ae_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for idx, (X_test, y_test) in enumerate(test_loader):\n",
    "            X_test = X_test.float().to(device)\n",
    "            pred_values = ae_model(X_test)\n",
    "            predicted_values = torch.cat((predicted_values, pred_values.cpu().detach()), dim = 0)\n",
    "            output_values = torch.cat((output_values, y_test), dim = 0)\n",
    "            \n",
    "    \n",
    "    return predicted_values, output_values\n",
    "\n",
    "def evaluate_with_hooks(model, data_loader, activation_layer, device, nb_examples = 3000):\n",
    "    set_activations = []\n",
    "    activation = {}\n",
    "    predicted_values, output_values = [], []\n",
    "    \n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "            \n",
    "        return hook\n",
    "    \n",
    "    for n, model_layer in model.named_children():\n",
    "        if n == activation_layer:\n",
    "            h = model_layer.register_forward_hook(get_activation(activation_layer))\n",
    "    \n",
    "    model.eval()\n",
    "    total_values = 0\n",
    "    for idx, (X_test, y_test) in tqdm(enumerate(data_loader)):\n",
    "        X_test = X_test.float().to(device)\n",
    "        output = model(X_test)\n",
    "        predicted_values.extend(output.reshape(-1,).detach().cpu().numpy())\n",
    "        output_values.append(y_test.detach().numpy())\n",
    "        set_activations.append(activation[activation_layer])\n",
    "        total_values += X_test.shape[0]\n",
    "        \n",
    "    return set_activations, predicted_values, output_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9e61f2",
   "metadata": {},
   "source": [
    "### Retrieiving activation for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306510c",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_train, _, _ = evaluate_with_hooks(cnn_model, training_loader, 'conv1', device, nb_examples = 3000)\n",
    "tensor_activations_train = torch.Tensor()\n",
    "for s in tqdm(activations_train):\n",
    "    tensor_activations_train = torch.cat((tensor_activations_train, s.detach().cpu()), dim = 0)\n",
    "tensor_activations_train = tensor_activations_train.reshape(-1, np.prod(tensor_activations_train.shape[1:]))\n",
    "\n",
    "act_full_train = ActivationsDataset(tensor_activations_train)\n",
    "act_full_train_loader = DataLoader(act_full_train, batch_size = 16, shuffle = True)\n",
    "\n",
    "ae_model_full = AE_all(160)\n",
    "set_ae_epochs = fit_ae_model(ae_model_full, act_full_train_loader, device, nb_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d090e",
   "metadata": {},
   "source": [
    "### Drift Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d126a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is responsible for extracting the activations of the convolutional layer ('conv1')\n",
    "def retrieve_activation(X_test, cnn_model):\n",
    "    set_activations = []\n",
    "    activation = {}\n",
    "    activation_layer = 'conv1'\n",
    "    \n",
    "    def get_activation(name):\n",
    "        def hook(model, input, output):\n",
    "            activation[name] = output.detach().clone()\n",
    "\n",
    "        return hook\n",
    "\n",
    "    for n, model_layer in cnn_model.named_children():\n",
    "        if n == activation_layer:\n",
    "            h = model_layer.register_forward_hook(get_activation(activation_layer))\n",
    "    cnn_model.eval()\n",
    "    X_test = X_test.float().to(device)\n",
    "    cnn_output = cnn_model(X_test)\n",
    "    set_activations = activation[activation_layer]\n",
    "    set_features_test = torch.Tensor(set_activations)\n",
    "    set_features_test = set_features_test.reshape(-1, np.prod(set_features_test.size()[1:]))\n",
    "    \n",
    "    h.remove()\n",
    "    return set_features_test, cnn_output\n",
    "\n",
    "# This function retrieves the latent representation of the Autoencoder\n",
    "def get_low_rank_encoded_values(X_test, cnn_model, ae_model):\n",
    "    set_features_test, _ = retrieve_activation(X_test, cnn_model)\n",
    "    ae_model_full.eval()\n",
    "    with torch.no_grad():\n",
    "        set_features_test = set_features_test.float().to(device)\n",
    "        low_rank_space = ae_model_full.encoder(set_features_test)\n",
    "        \n",
    "    return low_rank_space\n",
    "\n",
    "# The drift simulation and retrieval of latent representation of values upon their replacement\n",
    "def run_experiment(f):\n",
    "    predicted_values, output_values = torch.Tensor(), torch.Tensor()\n",
    "    cnn_model_output, orig_values = torch.Tensor(), torch.Tensor()\n",
    "    starting_value = 16 * 120\n",
    "    feature_to_replaced = f\n",
    "    last_batch = []\n",
    "    # explanation = torch.Tensor()\n",
    "    set_encoded_values = torch.Tensor()\n",
    "    drifted_encoded_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (X_test, y_test) in tqdm(enumerate(testing_loader)):\n",
    "            if idx < 120:\n",
    "                last_batch = [X_test, y_test]\n",
    "\n",
    "            else:\n",
    "                for idx_n in range(X_test.shape[0]):\n",
    "                    replacement_values = torch.zeros_like(X_test[idx_n][:, feature_to_replaced]) + (std.mean_[feature_to_replaced] + 2 * np.sqrt(std.mean_[feature_to_replaced]))\n",
    "                    replacement_values = (replacement_values - std.mean_[feature_to_replaced]) / (np.sqrt(std.var_[feature_to_replaced]))\n",
    "                    X_test[idx_n][:, feature_to_replaced] = replacement_values.clone()\n",
    "\n",
    "            if idx == 240:\n",
    "                break\n",
    "\n",
    "            set_features_test, cnn_output = retrieve_activation(X_test, cnn_model)\n",
    "            orig_values = torch.cat((orig_values, y_test), dim = 0)\n",
    "            cnn_model_output = torch.cat((cnn_model_output, cnn_output.reshape(-1,).detach().cpu()))\n",
    "            \n",
    "            if idx < 120: \n",
    "                ae_model_full.eval()\n",
    "                with torch.no_grad():\n",
    "                    set_features_test = set_features_test.float().to(device)\n",
    "                    low_rank_space = ae_model_full.encoder(set_features_test)\n",
    "                    set_encoded_values = torch.cat((set_encoded_values, low_rank_space.cpu().detach()), dim = 0)\n",
    "            else:\n",
    "                d_values = {}\n",
    "                for i in range(5): # The feature values\n",
    "                    new_X = X_test.clone()\n",
    "                    instance_batch = last_batch[0]\n",
    "                    for idx_n in range(X_test.shape[0]):\n",
    "                        replacement_values = torch.zeros_like(instance_batch[idx_n][:, i])\n",
    "                        new_X[idx_n][:, i] = replacement_values.clone()\n",
    "                    d_values[i] = get_low_rank_encoded_values(new_X, cnn_model, ae_model_full).cpu().detach()\n",
    "                drifted_encoded_values.append(d_values)\n",
    "                \n",
    "    return drifted_encoded_values, set_encoded_values, cnn_model_output, orig_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49afaf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = next(iter(testing_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bcab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data representative\n",
    "\n",
    "new_X = X_test.clone()\n",
    "for i in range(new_X.shape[0]):\n",
    "    new_X[i, :] = torch.zeros_like(new_X[i, :]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436835c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The latent representative of the training data\n",
    "\n",
    "set_encoded_values = torch.Tensor()\n",
    "set_features_test, _ = retrieve_activation(new_X, cnn_model)\n",
    "ae_model_full.eval()\n",
    "with torch.no_grad():\n",
    "    set_features_test = set_features_test.float().to(device)\n",
    "    low_rank_space = ae_model_full.encoder(set_features_test)\n",
    "    enc_vals = torch.cat((set_encoded_values, low_rank_space.cpu().detach()), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c9ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation of the drifting feature 0 (temperature in our case)\n",
    "\n",
    "all_drift_enc_f0 = {}\n",
    "all_nodrift_enc_f0 = {}\n",
    "all_cnn_output_f0 = {}\n",
    "all_orig_values_f0 = {}t_enc, cnn_output, orig_values = run_experiment(0)\n",
    "    all_d\n",
    "for exp in tqdm(range(1, 31)):\n",
    "    drift_enc, no_drifrift_enc_f0[f'exp_{exp}'] = drift_enc\n",
    "    all_nodrift_enc_f0[f'exp_{exp}'] = no_drift_enc    \n",
    "    all_cnn_output_f0[f'exp_{exp}'] = cnn_output        \n",
    "    all_orig_values_f0[f'exp_{exp}'] = orig_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef732a",
   "metadata": {},
   "source": [
    "### Calculate Minkowski Distance and detection accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a428f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import minkowski\n",
    "\n",
    "set_dist_v = []\n",
    "\n",
    "for exp in all_nodrift_enc_f0.keys():\n",
    "    set_encoded_mean = []\n",
    "    exp_no_drift_values = all_nodrift_enc_f0[exp]\n",
    "    exp_drift_values = all_drift_enc_f0[exp]\n",
    "    \n",
    "    for i in range(0, 5):\n",
    "        set_values = []\n",
    "        for k in range(len(exp_drift_values)):\n",
    "            set_drift_vals = torch.mean(exp_drift_values[k][i], dim = 0).numpy()\n",
    "            distance_mink = minkowski(torch.mean(enc_vals,dim=0),  set_drift_vals, 16)\n",
    "\n",
    "            set_values.append(distance_mink)\n",
    "        set_encoded_mean.append(set_values)\n",
    "    set_dist_v.append(set_encoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58a9135",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist_v = np.array(set_dist_v)\n",
    "set_accuracies = []\n",
    "for ex in range(set_dist_v.shape[0]):\n",
    "    all_args = np.argmin(set_dist_v[ex], axis = 0)\n",
    "    perc = np.sum(all_args == 0) / len(all_args)\n",
    "    set_accuracies.append(perc)\n",
    "print(np.mean(set_accuracies), np.std(set_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ab83f",
   "metadata": {},
   "source": [
    "### An example of calculating average distance (this is with temperature) -- Equivalent to Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_means_values = []\n",
    "for exp in range(set_dist_v.shape[0]):\n",
    "    mean_dist = np.mean(set_dist_v[exp], axis = 1)\n",
    "    set_means_values.append(mean_dist)\n",
    "set_means_values=np.array(set_means_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43020eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style = 'darkgrid')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15, 9))\n",
    "\n",
    "markers = ['x', 'o', '^', '*', '+']\n",
    "set_features = ['temperature', 'humidity', 'pressure', 'CO2', 'PIR']\n",
    "\n",
    "for idx in range(set_means_values.shape[1]):\n",
    "    plt.plot(set_means_values[:, idx],\n",
    "            marker = markers[idx], label = set_features[idx], markevery = 1, ms = 20)\n",
    "\n",
    "plt.tick_params(labelsize = 35)\n",
    "plt.legend(set_features, fontsize = 25)\n",
    "plt.xlabel(\"Experiment Number\", fontsize = 40)\n",
    "plt.ylabel(\"Minkowski Distance\", fontsize = 40)\n",
    "plt.title(\"Distance of features with drifting temperature\", fontsize = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
